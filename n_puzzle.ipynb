{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Computational Intelligence 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "from queue import *\n",
    "from random import *\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "RANDOMIZE_STEPS = 100_000\n",
    "\n",
    "action = namedtuple('Action', ('pos1', 'pos2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Variant\n",
    "_You can choose to pursuit your own goal.<br> Just set down here in_ ___GOAL_STATE___ _variable the sequence to reach._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Default game: search for number ordered increasing\n",
    "default_game = True \n",
    "\n",
    "#   If we wanna search a Specific configuration, ENTER here the configuration following the rules:\n",
    "#   -   MUST contain ONLY one \"0\";\n",
    "#   -   write number from 1 to PUZZLE_DIM**2 - 1 in a list\n",
    "\n",
    "GOAL_STATE = [1, 2, 3, 0]\n",
    "\n",
    "if not default_game:\n",
    "    if GOAL_STATE.count(0) != 1:\n",
    "        print(\"You insered too many 0s in your goal state!\\n\", GOAL_STATE)\n",
    "        exit(1)\n",
    "\n",
    "    if len(set(GOAL_STATE)) != PUZZLE_DIM**2:\n",
    "        print(\"You haven't created a feasible solution!\\n\",\n",
    "              f\"--> Remeber that the goal must be a {PUZZLE_DIM}x{PUZZLE_DIM} matrix,\\n\",\n",
    "              f\"    with all the number from 0 to {PUZZLE_DIM-1}!\\n\", GOAL_STATE)\n",
    "        exit(1)\n",
    "\n",
    "    GOAL_STATE = np.array(GOAL_STATE).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "else:\n",
    "    GOAL_STATE = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "GOAL_STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_check(state: np.ndarray) -> bool:\n",
    "    return np.array_equal(state, GOAL_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_loop(state: np.ndarray, visited_state) -> bool:\n",
    "    if all(isinstance(item, np.ndarray) for item in visited_state):\n",
    "        return any(np.array_equal(state, s) for s in visited_state)\n",
    "    else:\n",
    "        return any(np.array_equal(state, s.board) for s in visited_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 6 4]\n",
      " [2 1 7]\n",
      " [0 5 8]]\n"
     ]
    }
   ],
   "source": [
    "#   Random initialize the game board   #\n",
    "INITIAL_STATE = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for _ in range(RANDOMIZE_STEPS):\n",
    "    INITIAL_STATE = do_action(INITIAL_STATE, choice(available_actions(INITIAL_STATE)))\n",
    "print(INITIAL_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing:   0%|          | 11/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved in 11 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "state = INITIAL_STATE\n",
    "\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    #print(state)\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "    if solution_check(state):\n",
    "        break\n",
    "print(f\"Solved in {r:,} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH SEARCH STRATEGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth-First Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth-First: 2it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [3 2]] \n",
      "\n",
      "2\n",
      "[[1 0]\n",
      " [3 2]] \n",
      "\n",
      "2\n",
      "Solved in 3 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frontier = deque([INITIAL_STATE])\n",
    "\n",
    "explored_state = list()\n",
    "#   action_sequence = list()\n",
    "state = frontier.pop()\n",
    "explored_state.append(state)\n",
    "explored_node = 1\n",
    "\n",
    "with tqdm(total=None, desc=\"Depth-First\") as pbar:\n",
    "    while not solution_check(state):\n",
    "        print(state, \"\\n\")\n",
    "        for a in available_actions(state):\n",
    "            new_state = do_action(state, a)\n",
    "            if not avoid_loop(new_state, explored_state):\n",
    "                frontier.appendleft(new_state)\n",
    "\n",
    "        print(len(frontier))\n",
    "        state = frontier.popleft()\n",
    "        explored_state.append(state)\n",
    "        explored_node += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(f\"Solved in {explored_node:,} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth-First Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth-First: 7it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved in 8 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frontier = deque([INITIAL_STATE])\n",
    "\n",
    "explored_state = list()\n",
    "#   action_sequence = list()\n",
    "state = frontier.pop()\n",
    "explored_state.append(state)\n",
    "explored_node = 1\n",
    "\n",
    "with tqdm(total=None, desc=\"Depth-First\") as pbar:\n",
    "    \n",
    "    while not solution_check(state):\n",
    "        actions = available_actions(state)\n",
    "\n",
    "        for a in actions:\n",
    "            new_state = do_action(state, a)\n",
    "            if not avoid_loop(new_state, explored_state):\n",
    "                frontier.append(new_state)\n",
    "\n",
    "        #print(len(frontier))\n",
    "        state = frontier.popleft()\n",
    "        explored_state.append(state)\n",
    "        explored_node += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(f\"Solved in {explored_node:,} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A* Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(state: np.ndarray) -> int:\n",
    "    '''\n",
    "        Use the classic distance definition, of each point from its correct position, as cost\n",
    "    '''\n",
    "    n = state.shape[0]\n",
    "    distance = 0\n",
    "\n",
    "    for (i, j), tile in np.ndenumerate(state):\n",
    "        if tile == 0:\n",
    "            continue\n",
    "\n",
    "        target_i, target_j = divmod(tile-1, n)\n",
    "        distance += abs(i - target_i) + abs(j - target_j)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, board: np.ndarray, previous_state: \"Node\") -> None:\n",
    "        self.board = board      # Game state\n",
    "        self.previous_state = previous_state    # Parent Node\n",
    "        if previous_state is None:      # Actual Cost to reach this Node\n",
    "            self.g = 0\n",
    "        else:\n",
    "            self.g = previous_state.g + 1\n",
    "        self.h = heuristic(board)\n",
    "        self.f = (self.g) + (self.h)    # f(x) = g(x) + h(x)\n",
    "\n",
    "    def __eq__(self, other: \"Node\"):\n",
    "        return np.array_equal(self.board, other.board)\n",
    "\n",
    "    def __lt__(self, other: \"Node\"):\n",
    "        return (self.f, self.g) < (other.f, other.g)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Rappresentazione leggibile del nodo.\n",
    "        \"\"\"\n",
    "        stato_str = '\\n'.join([' '.join(map(str, riga)) for riga in self.board])\n",
    "        return f\"Move number: {self.g}\\nBoard:\\n{stato_str}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_useless_state(node: \"Node\", frontier: PriorityQueue[Node]) -> bool:\n",
    "    for existing_node in frontier:\n",
    "        if existing_node == node :\n",
    "            if existing_node < node:\n",
    "                return True\n",
    "        \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_star(prob):\n",
    "    frontier = PriorityQueue()\n",
    "\n",
    "    explored_state = list()\n",
    "    state = Node(prob, None)\n",
    "    explored_state.append(state)\n",
    "\n",
    "    while not solution_check(state.board):\n",
    "        for a in available_actions(state.board):\n",
    "            new_node = Node(do_action(state.board, a), state)\n",
    "            if not avoid_loop(new_node.board, explored_state):\n",
    "                frontier.put(new_node)\n",
    "        state = frontier.get()\n",
    "        #print(state.h)\n",
    "        explored_state.append(state)\n",
    "\n",
    "    return explored_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_node = A_star(INITIAL_STATE)[-1]\n",
    "path = []\n",
    "while current_node:\n",
    "    path.append(current_node)\n",
    "    current_node = current_node.previous_state\n",
    "print(f\"Visited {len(explored_state):,} states. Problem can be solved in {len(path)-1} moves !\")\n",
    "\n",
    "path[::-1]  # Return reversed path from start to goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_initialization(puzzleDimension: int) -> np.ndarray:\n",
    "    #   Random initialize the game board   #\n",
    "    INITIAL_STATE = np.array([i for i in range(1, puzzleDimension**2)] + [0]).reshape((puzzleDimension, puzzleDimension))\n",
    "    for _ in range(RANDOMIZE_STEPS):\n",
    "        INITIAL_STATE = do_action(INITIAL_STATE, choice(available_actions(INITIAL_STATE)))\n",
    "    return INITIAL_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 2x2 -> 1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for PUZZLE_DIM in range(2, 8):\n",
    "    print(f\"Dimensions: {PUZZLE_DIM}x{PUZZLE_DIM} -> \", end=\"\")\n",
    "    prob = random_initialization(PUZZLE_DIM)\n",
    "    start = time()\n",
    "    sol = A_star(prob)\n",
    "    end = time()\n",
    "    print(f\"Steps: {len(sol) - 1} ({(end - start):.3f}s)\", end=\"\")\n",
    "    if PUZZLE_DIM < 4:\n",
    "        sol = A_star(prob)\n",
    "        print(f\" (Optimal #steps: {len(sol) - 1})\", end=\"\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
